{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sheet 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Logistic regression: an LLM lie detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how you can load a dataset of LLM activations. Use a new Datamanager if you want to have a new dataset. Use `add_dataset` multiple times on the same data manager if you want to combine datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1196, 4096]) torch.Size([1196])\n"
     ]
    }
   ],
   "source": [
    "from lie_detection_utils import DataManager\n",
    "\n",
    "path_to_datasets = \"data/lie_detection/datasets\"\n",
    "path_to_acts = \"data/lie_detection/acts\"\n",
    "\n",
    "# check if the datasets and activations are available\n",
    "assert os.path.exists(path_to_datasets), \"The path to the datasets does not exist.\"\n",
    "assert os.path.exists(path_to_acts), \"The path to the activations does not exist.\"\n",
    "\n",
    "# these are the different datasets containing true and false factual statements about different topics\n",
    "dataset_names = [\"cities\", \"neg_cities\", \"sp_en_trans\", \"neg_sp_en_trans\"]\n",
    "dataset_name = dataset_names[0] # choose some dataset from the above datasets, index \"0\" loads the \"cities\" dataset for example\n",
    "\n",
    "# the dataloader automatically loads the training data for us\n",
    "dm = DataManager()\n",
    "dm.add_dataset(dataset_name, \"Llama3\", \"8B\", \"chat\", layer=12, split=0.8, center=False,\n",
    "                device='cpu', path_to_datasets=path_to_datasets, path_to_acts=path_to_acts)\n",
    "acts_train, labels_train = dm.get('train') # train set\n",
    "acts_test, labels_test = dm.get('val')\n",
    "print(acts_train.shape, labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        statement  label       city  \\\n",
      "0             The city of Krasnodar is in Russia.      1  Krasnodar   \n",
      "1       The city of Krasnodar is in South Africa.      0  Krasnodar   \n",
      "2                  The city of Lodz is in Poland.      1       Lodz   \n",
      "3  The city of Lodz is in the Dominican Republic.      0       Lodz   \n",
      "4            The city of Maracay is in Venezuela.      1    Maracay   \n",
      "5                The city of Maracay is in China.      0    Maracay   \n",
      "6              The city of Baku is in Azerbaijan.      1       Baku   \n",
      "7                 The city of Baku is in Ukraine.      0       Baku   \n",
      "8                  The city of Baoji is in China.      1      Baoji   \n",
      "9              The city of Baoji is in Guatemala.      0      Baoji   \n",
      "\n",
      "                  country correct_country  \n",
      "0                  Russia          Russia  \n",
      "1            South Africa          Russia  \n",
      "2                  Poland          Poland  \n",
      "3  the Dominican Republic          Poland  \n",
      "4               Venezuela       Venezuela  \n",
      "5                   China       Venezuela  \n",
      "6              Azerbaijan      Azerbaijan  \n",
      "7                 Ukraine      Azerbaijan  \n",
      "8                   China           China  \n",
      "9               Guatemala           China  \n"
     ]
    }
   ],
   "source": [
    "# have a look at the statements that were fed to the LLM to produce the activations:\n",
    "df = pd.read_csv(f\"{path_to_datasets}/{dataset_name}.csv\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Create and train the Logistic Regression model\n",
    "model = LogisticRegression(penalty=None, max_iter=1000)  # No regularization\n",
    "model.fit(acts_train, labels_train) \n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(acts_test)\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(labels_test, predictions)\n",
    "print(f\"Test set accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an accuracy of 100 % for all four data sets, so the activation vectors are linearly separable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on cities dataset\n",
    "train_dataset = \"cities\"\n",
    "dm.add_dataset(train_dataset, \"Llama3\", \"8B\", \"chat\", layer=12, split=0.8, center=False,\n",
    "                device='cpu', path_to_datasets=path_to_datasets, path_to_acts=path_to_acts)\n",
    "acts_train, labels_train = dm.get('train') # train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy on neg_cities: 75.00%\n",
      "Test set accuracy on sp_en_trans: 74.37%\n",
      "Test set accuracy on neg_sp_en_trans: 71.83%\n"
     ]
    }
   ],
   "source": [
    "# No regularization\n",
    "\n",
    "# Create and train the Logistic Regression model\n",
    "model = LogisticRegression(penalty=None, max_iter=1000)\n",
    "model.fit(acts_train, labels_train)\n",
    "\n",
    "# Evaluate on other datasets\n",
    "for test_dataset in dataset_names:\n",
    "    if test_dataset == train_dataset:\n",
    "        continue\n",
    "    dm.add_dataset(test_dataset, \"Llama3\", \"8B\", \"chat\", layer=12, split=0.8, center=False,\n",
    "                    device='cpu', path_to_datasets=path_to_datasets, path_to_acts=path_to_acts)\n",
    "    acts_test, labels_test = dm.get('val')\n",
    "    predictions = model.predict(acts_test)\n",
    "    accuracy = accuracy_score(labels_test, predictions)\n",
    "    print(f\"Test set accuracy on {test_dataset}: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy on neg_cities: 75.47%\n",
      "Test set accuracy on sp_en_trans: 75.20%\n",
      "Test set accuracy on neg_sp_en_trans: 76.82%\n"
     ]
    }
   ],
   "source": [
    "# With regularization\n",
    "\n",
    "# Create and train the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)  # With regularization\n",
    "model.fit(acts_train, labels_train)\n",
    "\n",
    "# Evaluate on other datasets\n",
    "for test_dataset in dataset_names:\n",
    "    if test_dataset == train_dataset:\n",
    "        continue\n",
    "    dm.add_dataset(test_dataset, \"Llama3\", \"8B\", \"chat\", layer=12, split=0.8, center=False,\n",
    "                    device='cpu', path_to_datasets=path_to_datasets, path_to_acts=path_to_acts)\n",
    "    acts_test, labels_test = dm.get('val')\n",
    "    predictions = model.predict(acts_test)\n",
    "    accuracy = accuracy_score(labels_test, predictions)\n",
    "    print(f\"Test set accuracy on {test_dataset}: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that all performances are >50%, so the results are above chance, yet do not fully generalize to other topics. We can further see that the accuracy drops when negation is introduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine cities and neg cities datasets for training\n",
    "train_datasets = [\"cities\", \"neg_cities\"]\n",
    "acts_train_list = []\n",
    "labels_train_list = []  \n",
    "for dataset in train_datasets:\n",
    "    dm.add_dataset(dataset, \"Llama3\", \"8B\", \"chat\", layer=12, split=0.8, center=False,\n",
    "                    device='cpu', path_to_datasets=path_to_datasets, path_to_acts=path_to_acts)\n",
    "    acts, labels = dm.get('train')\n",
    "    acts_train_list.append(acts)\n",
    "    labels_train_list.append(labels)\n",
    "acts_train = np.concatenate(acts_train_list)\n",
    "labels_train = np.concatenate(labels_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy on sp_en_trans: 99.60%\n",
      "Test set accuracy on neg_sp_en_trans: 99.60%\n"
     ]
    }
   ],
   "source": [
    "# Create and train the Logistic Regression model\n",
    "model = LogisticRegression(penalty=None, max_iter=1000)  # No regularization\n",
    "model.fit(acts_train, labels_train) \n",
    "\n",
    "# Evaluate on sp_en_trans and neg_sp_en_trans datasets\n",
    "test_datasets = [\"sp_en_trans\", \"neg_sp_en_trans\"]\n",
    "for test_dataset in test_datasets:  \n",
    "    dm.add_dataset(test_dataset, \"Llama3\", \"8B\", \"chat\", layer=12, split=0.8, center=False,\n",
    "                    device='cpu', path_to_datasets=path_to_datasets, path_to_acts=path_to_acts)\n",
    "    acts_test, labels_test = dm.get('val')\n",
    "    predictions = model.predict(acts_test)\n",
    "    accuracy = accuracy_score(labels_test, predictions)\n",
    "    print(f\"Test set accuracy on {test_dataset}: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Log-sum-exp and soft(arg)max\n",
    "### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Linear regions of MLPs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
